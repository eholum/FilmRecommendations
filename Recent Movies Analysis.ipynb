{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve, urlopen\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re, string\n",
    "from itertools import islice\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recent_years = {2015, 2014, 2013, 2012}\n",
    "\n",
    "count = 0\n",
    "for m in movies:\n",
    "    if movies[m][1] in recent_years:        \n",
    "        recent_movies[m] = movies[m]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3862\n",
      "3772\n"
     ]
    }
   ],
   "source": [
    "def prepare_datasets(): \n",
    "    f = open(\"recent_movies.pickle\", 'rb')\n",
    "    recent_movies = pickle.load(f)\n",
    "    del(f)\n",
    "\n",
    "    f = open(\"recent_reviews.pickle\", 'rb')\n",
    "    recent_reviews = pickle.load(f)\n",
    "    del(f)\n",
    "    \n",
    "    return [recent_movies, recent_reviews]\n",
    "\n",
    "recent_movies, recent_reviews = prepare_datasets()\n",
    "print(len(recent_movies))\n",
    "print(len(recent_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A.O. Scott',\n",
       " 'New York Times',\n",
       " None,\n",
       " 'http://www.nytimes.com/2015/05/15/movies/review-mad-max-fury-road-still-angry-after-all-these-years.html?partner=rss&emc=rss']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mad Max: Fury Road\n",
    "recent_reviews[122882]['A.O. Scott']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3862"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recent_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunks(data, SIZE):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        yield {k for k in islice(it, SIZE)}\n",
    "\n",
    "recent_movies_chunks = chunks(recent_movies, SIZE=5)\n",
    "recent_movies_chunks = [m for m in recent_movies_chunks]\n",
    "\n",
    "print(sum([len(m) for m in recent_movies_chunks]))\n",
    "\n",
    "type(recent_movies_chunks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_url = \"http://www.rottentomatoes.com\"\n",
    "rt_search_url = rt_url + \"/search/?search=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "ab%20c%25C3%25A5\n"
     ]
    }
   ],
   "source": [
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)\n",
    "\n",
    "print(is_ascii('abc'))\n",
    "print(is_ascii('à'))\n",
    "\n",
    "def encode_unicode(title):\n",
    "    \"\"\"\n",
    "    replaces unicode characters with percent encodings.\n",
    "    \"\"\"\n",
    "    tmp = ''\n",
    "    for i in range(0, len(title)):\n",
    "        c = title[i]\n",
    "        if is_ascii(c):\n",
    "            tmp += c\n",
    "        else:\n",
    "            tmp += urllib.parse.quote(c)\n",
    "    tmp = tmp.encode(\"utf-8\")\n",
    "    return urllib.parse.quote(tmp)\n",
    "        \n",
    "print(encode_unicode(\"ab cå\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.rottentomatoes.com/search/?search=mad+max+fury+road\n",
      "http://www.rottentomatoes.com/search/?search=tom%20at%20the%20farm%20%28tom%20%25C3%25A0%20la%20ferme%29\n"
     ]
    }
   ],
   "source": [
    "exclude = set(string.punctuation.replace('(','').replace(')', '').replace(\"'\",''))\n",
    "\n",
    "def get_search_url(movie):\n",
    "    \"\"\"\n",
    "    Finds the rotten tomatoes URL for the given title.\n",
    "    \"\"\"\n",
    "    title = ''.join(ch for ch in movie[0] if ch not in exclude).lower()\n",
    "    \n",
    "    if not is_ascii(title):\n",
    "        # Percent encode UNICODE characters\n",
    "        title = encode_unicode(title)\n",
    "        \n",
    "    search_url = rt_search_url + '+'.join(title.split(' '))\n",
    "    \n",
    "    return search_url\n",
    "\n",
    "print(get_search_url(recent_movies[122882]))\n",
    "print(get_search_url(recent_movies[108787]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "def convert_letter_grade(score):\n",
    "    \"\"\"\n",
    "    Converts letter grade to score.\n",
    "    \"\"\"\n",
    "    score = score.lower()\n",
    "    \n",
    "    if score == 'a':\n",
    "        return 1\n",
    "    \n",
    "    letter = score[0]\n",
    "    sign = None\n",
    "    if len(score) > 1:\n",
    "        sign = score[1]\n",
    "    \n",
    "    s = None\n",
    "    if letter == 'a':\n",
    "        s = .80\n",
    "    elif letter == 'b':\n",
    "        s = .60\n",
    "    elif letter == 'c':\n",
    "        s = .40\n",
    "    elif letter == 'd':\n",
    "        s = .20\n",
    "    elif letter == 'f':\n",
    "        s = 0\n",
    "        \n",
    "    if sign == '+':\n",
    "        s += .1\n",
    "    elif sign == '-':\n",
    "        s -= .1\n",
    "        \n",
    "    return s\n",
    "\n",
    "def compute_score(score):\n",
    "    \"\"\"\n",
    "    Takes a score from rotten tomatoes and converts it to a score between 0 and 1. 0 being terrible\n",
    "    and 1 being perfect. If there isn't a score, returns -1.\n",
    "    \"\"\"\n",
    "    if not score:\n",
    "        return None\n",
    "    \n",
    "    if '/' in score:\n",
    "        num, denom = score.split('/')\n",
    "        return float(num)/float(denom)\n",
    "    \n",
    "    try:\n",
    "        return convert_letter_grade(score)\n",
    "    except:\n",
    "        return score\n",
    "\n",
    "print(compute_score(\"3/4\"))\n",
    "print(compute_score(\"b+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "def process_review(review):\n",
    "    reviewer_and_source = review.find(\"div\", {\"class\" : \"critic_name\"})\n",
    "    link_and_score = review.find(\"div\", {\"class\" : \"small subtle\"})\n",
    "    \n",
    "    source = reviewer_and_source.find('em').getText()\n",
    "    reviewer = reviewer_and_source.find('a')\n",
    "    \n",
    "    if not reviewer:\n",
    "        reviewer = source\n",
    "    else:\n",
    "        reviewer = reviewer.getText()\n",
    "\n",
    "    review_link = link_and_score.find('a')\n",
    "    if (review_link):\n",
    "        review_link = review_link['href']\n",
    "\n",
    "    score = link_and_score.getText().split('Original Score:')\n",
    "    if len(score) > 1:\n",
    "        score = score[1].strip()\n",
    "    else:\n",
    "        score = None\n",
    "    \n",
    "    return [reviewer, source, compute_score(score), review_link]\n",
    "    \n",
    "    \n",
    "page_suffix = \"?page=%d&sort=\"\n",
    "def get_reviews(url):\n",
    "    \"\"\"\n",
    "    Given an RT reviews page, this grabs links to all of the reviews on the page.\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return {}\n",
    "    \n",
    "    if not (url[-1] == '/'):\n",
    "        url += '/'\n",
    "    \n",
    "    all_reviews = {}\n",
    "    for i in range(1,20):\n",
    "        page = url + (page_suffix % i)\n",
    "        \n",
    "        try:\n",
    "            response = urlopen(page)\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        soup = BeautifulSoup(response)\n",
    "        reviews = soup.findAll(\"div\", { \"class\" : \"row review_table_row\" })\n",
    "    \n",
    "        for review in reviews:\n",
    "            data = process_review(review)\n",
    "            all_reviews[data[0]] = data\n",
    "    return all_reviews\n",
    "\n",
    "toy_story_reviews = get_reviews(\"http://www.rottentomatoes.com/m/toy_story/reviews\")\n",
    "print(len(toy_story_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "http://www.rottentomatoes.com/m/mad_max_fury_road/reviews\n",
      "http://www.rottentomatoes.com/m/tom_at_the_farm/reviews\n"
     ]
    }
   ],
   "source": [
    "def get_movie_url(movie):\n",
    "    \"\"\"\n",
    "    Given a movie, determines the rotten tomatoes URL for the critics' reviews of that movie.\n",
    "    \"\"\"\n",
    "    search_url = get_search_url(movie)\n",
    "    \n",
    "    response = urlopen(search_url)\n",
    "    soup = BeautifulSoup(response)\n",
    "    \n",
    "    url = None\n",
    "    \n",
    "    # No results tag\n",
    "    if (soup.find(\"h1\", {\"class\" : \"center noresults\"})):\n",
    "        return url\n",
    "    \n",
    "    if \"search results\" in soup.find(\"title\").text.lower():\n",
    "        # Find the movie with the correct year\n",
    "        year = movie[1]\n",
    "        results = soup.findAll(\"li\", {\"class\" : \"media bottom_divider clearfix\"})\n",
    "        \n",
    "        for i in results:\n",
    "            result_year = i.find(\"span\", {\"class\" : \"movie_year\"}).getText().strip()[1:5]\n",
    "            if not result_year:\n",
    "                continue\n",
    "            result_year = int(result_year)\n",
    "            result_url = rt_url + i.find(\"a\")[\"href\"]\n",
    "            \n",
    "            title = i.find(\"div\", {\"class\" : \"nomargin media-heading bold\"}).find(\"a\").getText().lower()\n",
    "\n",
    "            if year == result_year:\n",
    "                url = result_url\n",
    "                break\n",
    "    \n",
    "    else:\n",
    "        url = response.url.split('?')[0]\n",
    "\n",
    "    if url:\n",
    "        url = url + \"reviews\"\n",
    "    \n",
    "    return url\n",
    "\n",
    "\n",
    "# The battery, which isn't on rotten tomatoes\n",
    "print(get_movie_url(recent_movies[103816]))\n",
    "\n",
    "# Should be mad max\n",
    "print(get_movie_url(recent_movies[122882]))\n",
    "\n",
    "# Foreign film with unicode\n",
    "print(get_movie_url(recent_movies[108787]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3772"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recent_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"recent_reviews/\"\n",
    "\n",
    "def pickle_reviews(mid, rs):\n",
    "    \"\"\"\n",
    "    dump pickle of reviews to disk. Super inefficient but I really don't want to lose this data. \n",
    "    Would be better to setup SQL database but I'm cheap.\n",
    "    \"\"\"\n",
    "    f = open(\"%s%d.pickle\" % (folder, mid), 'wb')\n",
    "    pickle.dump(rs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_url = []\n",
    "error_rev = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "len(recent_movies_chunks)\n",
    "\n",
    "# This obviously takes a really long time to do all chunks\n",
    "for i in range(0,0):\n",
    "    count += 1\n",
    "    if (count % 10 == 0):\n",
    "        print(count)\n",
    "    cur = recent_movies_chunks[i]\n",
    "    \n",
    "    for mid in cur:\n",
    "        \n",
    "        if mid in recent_reviews:\n",
    "            continue\n",
    "            \n",
    "        movie = recent_movies[mid]\n",
    "        \n",
    "        if len(movie) > 3:\n",
    "            url = movie[3]\n",
    "        else:\n",
    "            try:\n",
    "                url = get_movie_url(movie)\n",
    "                movie.append(url)\n",
    "            except Exception as ex:\n",
    "                error_url.append([mid, movie, ex])\n",
    "                continue\n",
    "                \n",
    "        try:\n",
    "            rs = get_reviews(url)\n",
    "        except Exception as ex:\n",
    "            error_rev.append([mid, movie, ex])\n",
    "            continue\n",
    "    \n",
    "        recent_reviews[mid] = rs\n",
    "        pickle_reviews(mid, rs)\n",
    "        \n",
    "        \n",
    "    f = open(\"recent_movies.pickle\", 'wb')\n",
    "    pickle.dump(recent_movies, f)\n",
    "    f = open(\"recent_reviews.pickle\", 'wb')\n",
    "    pickle.dump(recent_reviews, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123117"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in recent_reviews:\n",
    "    if len(recent_reviews[i]) > 0:\n",
    "        count += len(recent_reviews[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"error_url.pickle\", 'wb')\n",
    "pickle.dump(error_url, f)\n",
    "\n",
    "f = open(\"error_rev.pickle\", 'wb')\n",
    "pickle.dump(error_rev, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Susan Granger'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviewers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in recent_reviews:\n",
    "    reviews = recent_reviews[i]\n",
    "    title, year, genre, url = recent_movies[i]\n",
    "\n",
    "    for name in reviews:\n",
    "\n",
    "        if name not in reviewers:\n",
    "            reviewers[name] = {}\n",
    "        \n",
    "        rev, source, score, link = reviews[name]\n",
    "        reviewers[name][i] = [title, year, genre, source, score, url, link]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3772"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recent_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
