{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re, string\n",
    "from itertools import islice\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Complete List of Movies We Have Ratings For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileloc = \"/Volumes/Eriks HD/MLC Final/ml-latest/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_file = open(fileloc + \"movies.csv\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in csv.reader(open(fileloc + \"movies.csv\", newline=''), delimiter=',', quotechar='\\\"'):\n",
    "    lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_title(title):\n",
    "    title = title.strip()\n",
    "    return [title[0:-7], int(title[-5:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['40697', 'Babylon 5', 'Sci-Fi']\n",
      "['79607', 'Millions Game, The (Das Millionenspiel)', 'Action|Drama|Sci-Fi|Thriller']\n",
      "['87442', 'Bicycle, Spoon, Apple (Bicicleta, cullera, poma)', 'Documentary']\n",
      "['98063', 'Mona and the Time of Burning Love (Mona ja palavan rakkauden aika) (1983))', 'Drama']\n",
      "['107434', 'Diplomatic Immunity (2009– )', 'Comedy']\n",
      "['108548', 'Big Bang Theory, The (2007-)', 'Comedy']\n",
      "['112406', 'Brazil: In the Shadow of the Stadiums', 'Documentary']\n",
      "['113190', 'Slaying the Badger', 'Documentary']\n",
      "['115133', 'Tatort: Im Schmerz geboren', 'Crime']\n",
      "['115685', 'National Theatre Live: Frankenstein', 'Drama|Fantasy']\n",
      "['125571', 'The Court-Martial of Jackie Robinson', '(no genres listed)']\n",
      "['125632', 'In Our Garden', '(no genres listed)']\n",
      "['125958', 'Stephen Fry In America - New World', '(no genres listed)']\n",
      "['126438', 'Two: The Story of Roman & Nyro', 'Documentary|Drama']\n",
      "['126929', \"Li'l Quinquin\", '(no genres listed)']\n",
      "['127005', 'A Year Along the Abandoned Road', '(no genres listed)']\n",
      "['128612', 'Body/Cialo', 'Comedy|Drama|Mystery']\n",
      "['128734', 'Polskie gówno', 'Comedy|Musical']\n",
      "['129651', 'The Third Reich: The Rise & Fall', '(no genres listed)']\n",
      "['129705', 'My Own Man', '(no genres listed)']\n",
      "['129887', 'Moving Alan', '(no genres listed)']\n",
      "['130454', 'Michael Laudrup - en Fodboldspiller', '(no genres listed)']\n",
      "['132948', 'Doli Saja Ke Rakhna', '(no genres listed)']\n",
      "['134254', \"C'mon, Let's Live a Little\", '(no genres listed)']\n",
      "['134908', 'For a Book of Dollars', '(no genres listed)']\n",
      "['135145', 'Bad Boys 3', 'Action|Crime|Thriller']\n",
      "['135691', 'Señorita Justice', '(no genres listed)']\n",
      "['136299', 'Red Victoria', 'Comedy|Horror']\n",
      "['136880', 'Vaastupurush', '(no genres listed)']\n",
      "['137284', \"Sierra Leone's Refugee All Stars\", '(no genres listed)']\n",
      "['137292', \"L'uomo della carità\", '(no genres listed)']\n"
     ]
    }
   ],
   "source": [
    "movies = {}\n",
    "for i in range(1,len(lines)):\n",
    "    try:\n",
    "        line = lines[i]\n",
    "        idnum = int(line[0])\n",
    "        title, year = split_title(line[1])\n",
    "        genres = line[2].split('|')\n",
    "\n",
    "        movies[idnum] = [title, year, genres]\n",
    "        \n",
    "    except Exception as inst:\n",
    "        print(lines[i])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toy Story', 1995, ['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy']]\n",
      "['Heat', 1995, ['Action', 'Crime', 'Thriller']]\n",
      "['American President, The', 1995, ['Comedy', 'Drama', 'Romance']]\n",
      "['Casino', 1995, ['Crime', 'Drama']]\n",
      "['Get Shorty', 1995, ['Comedy', 'Crime', 'Thriller']]\n",
      "['Othello', 1995, ['Drama']]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,30,5):\n",
    "    print(movies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30075"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Rotten Tomatoes for Each Movie\n",
    "\n",
    "Not using their public API, but hopefully we'll only have to do this once. I don't think people take kindly to scrapers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30075\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "def prepare_datasets():\n",
    "    f = open(\"movies.pickle\", 'rb')\n",
    "    movies = pickle.load(f)\n",
    "    del(f)\n",
    "\n",
    "    f = open(\"reviews.pickle\", 'rb')\n",
    "    all_movie_reviews = pickle.load(f)\n",
    "    \n",
    "    return [movies, all_movie_reviews]\n",
    "\n",
    "movies, all_movie_reviews = prepare_datasets()\n",
    "print(len(movies))\n",
    "print(len(all_movie_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story',\n",
       " 1995,\n",
       " ['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy'],\n",
       " 'http://www.rottentomatoes.com/m/toy_story/reviews/']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort movies by date order\n",
    "movies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2}\n",
      "{3: 3, 4: 4, 5: 5}\n",
      "{8: 8, 6: 6, 7: 7}\n",
      "{9: 9}\n",
      "[500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 75]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunks(data, SIZE=500):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        yield {k:data[k] for k in islice(it, SIZE)}\n",
    "        \n",
    "for it in chunks({i:i for i in range(10)}, SIZE = 3):\n",
    "    print(it)\n",
    "\n",
    "movies_chunks = chunks(movies, SIZE=500)\n",
    "movies_chunks = [m for m in movies_chunks]\n",
    "\n",
    "print([len(m) for m in movies_chunks])\n",
    "\n",
    "type(movies_chunks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_url = \"http://www.rottentomatoes.com\"\n",
    "rt_search_url = rt_url + \"/search/?search=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.rottentomatoes.com/search/?search=city+hall\n",
      "http://www.rottentomatoes.com/search/?search=bottle+rocket\n",
      "http://www.rottentomatoes.com/search/?search=mr+wrong\n",
      "http://www.rottentomatoes.com/search/?search=unforgettable\n",
      "http://www.rottentomatoes.com/search/?search=happy+gilmore\n"
     ]
    }
   ],
   "source": [
    "exclude = set(string.punctuation.replace('(','').replace(')', '').replace(\"'\",''))\n",
    "\n",
    "def get_search_url(movie):\n",
    "    \"\"\"\n",
    "    Finds the rotten tomatoes URL for the given title.\n",
    "    \"\"\"\n",
    "    title = ''.join(ch for ch in movie[0] if ch not in exclude)\n",
    "    search_url = rt_search_url + '+'.join(title.lower().split(' '))\n",
    "    \n",
    "    return search_url\n",
    "\n",
    "for i in range(100,105):\n",
    "    print(get_search_url(movies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_letter_grade(score):\n",
    "    \"\"\"\n",
    "    Converts letter grade to score.\n",
    "    \"\"\"\n",
    "    score = score.lower()\n",
    "    \n",
    "    if score == 'a':\n",
    "        return 1\n",
    "    \n",
    "    letter = score[0]\n",
    "    sign = None\n",
    "    if len(score) > 1:\n",
    "        sign = score[1]\n",
    "    \n",
    "    s = None\n",
    "    if letter == 'a':\n",
    "        s = .80\n",
    "    elif letter == 'b':\n",
    "        s = .60\n",
    "    elif letter == 'c':\n",
    "        s = .40\n",
    "    elif letter == 'd':\n",
    "        s = .20\n",
    "    elif letter == 'f':\n",
    "        s = 0\n",
    "        \n",
    "    if sign == '+':\n",
    "        s += .1\n",
    "    elif sign == '-':\n",
    "        s -= .1\n",
    "        \n",
    "    return s\n",
    "\n",
    "def compute_score(score):\n",
    "    \"\"\"\n",
    "    Takes a score from rotten tomatoes and converts it to a score between 0 and 1. 0 being terrible\n",
    "    and 1 being perfect. If there isn't a score, returns -1.\n",
    "    \"\"\"\n",
    "    if not score:\n",
    "        return None\n",
    "    \n",
    "    if '/' in score:\n",
    "        num, denom = score.split('/')\n",
    "        return float(num)/float(denom)\n",
    "    \n",
    "    return convert_letter_grade(score)\n",
    "\n",
    "def process_review(review):\n",
    "    reviewer_and_source = review.find(\"div\", {\"class\" : \"critic_name\"})\n",
    "    link_and_score = review.find(\"div\", {\"class\" : \"small subtle\"})\n",
    "    \n",
    "    source = reviewer_and_source.find('em').getText()\n",
    "    reviewer = reviewer_and_source.find('a')\n",
    "    \n",
    "    if not reviewer:\n",
    "        reviewer = source\n",
    "    else:\n",
    "        reviewer = reviewer.getText()\n",
    "\n",
    "    review_link = link_and_score.find('a')\n",
    "    if (review_link):\n",
    "        review_link = review_link['href']\n",
    "\n",
    "    score = link_and_score.getText().split('Original Score:')\n",
    "    if len(score) > 1:\n",
    "        score = score[1].strip()\n",
    "    else:\n",
    "        score = None\n",
    "    \n",
    "    return [reviewer, source, compute_score(score), review_link]\n",
    "    \n",
    "    \n",
    "page_suffix = \"?page=%d&sort=\"\n",
    "def get_reviews(url):\n",
    "    \"\"\"\n",
    "    Given an RT reviews page, this grabs links to all of the reviews on the page.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not (url[-1] == '/'):\n",
    "        url += '/'\n",
    "    \n",
    "    all_reviews = {}\n",
    "    for i in range(1,20):\n",
    "        page = url + (page_suffix % i)\n",
    "        \n",
    "        try:\n",
    "            response = urlopen(page)\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        soup = BeautifulSoup(response)\n",
    "        reviews = soup.findAll(\"div\", { \"class\" : \"row review_table_row\" })\n",
    "    \n",
    "        for review in reviews:\n",
    "            data = process_review(review)\n",
    "            all_reviews[data[0]] = data\n",
    "    return all_reviews\n",
    "\n",
    "toy_story_review = get_reviews(\"http://www.rottentomatoes.com/m/toy_story/reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-51f69b0b7c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Should be the 3rd result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mget_movie_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m131258\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'movies' is not defined"
     ]
    }
   ],
   "source": [
    "def get_movie_url(movie):\n",
    "    \"\"\"\n",
    "    Given a movie, determines the rotten tomatoes URL for the critics' reviews of that movie.\n",
    "    \"\"\"\n",
    "    search_url = get_search_url(movie)\n",
    "    \n",
    "    response = urlopen(search_url)\n",
    "    soup = BeautifulSoup(response)\n",
    "    \n",
    "    if \"search results\" in soup.find(\"title\").text.lower():\n",
    "        # Find the first movie with the correct year and assume it's correct\n",
    "        year = movie[1]\n",
    "        results = soup.findAll(\"li\", {\"class\" : \"media bottom_divider clearfix\"})\n",
    "        \n",
    "        url = None\n",
    "        for i in results:\n",
    "            result_year = int(i.find(\"span\", {\"class\" : \"movie_year\"}).getText().strip()[1:5])\n",
    "            result_url = rt_url + i.find(\"a\")[\"href\"]\n",
    "            \n",
    "            title = i.find(\"div\", {\"class\" : \"nomargin media-heading bold\"}).find(\"a\").getText()\n",
    "\n",
    "            if year == result_year:\n",
    "                url = result_url\n",
    "                break\n",
    "    \n",
    "    else:\n",
    "        url = response.url.split('?')[0]\n",
    "\n",
    "    return url + \"reviews\"\n",
    "\n",
    "# Should be the 3rd result\n",
    "get_movie_url(movies[131258])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Project.ipynb          Recent Movies Analysis.ipynb movies.pickle                \u001b[34mrecent_reviews\u001b[m\u001b[m               reviews.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errored_movies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dump_data():\n",
    "    f = open(\"movies.pickle\", 'wb')\n",
    "    pickle.dump(movies, f)\n",
    "\n",
    "    f = open(\"reviews.pickle\", 'wb')\n",
    "    pickle.dump(all_movie_reviews, f)\n",
    "    \n",
    "dump_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500"
     ]
    }
   ],
   "source": [
    "for i in range(2,20):\n",
    "    selection = movies_chunks[i]\n",
    "    \n",
    "    print(len(movies_chunks[i]))\n",
    "    \n",
    "    for i in selection:\n",
    "        movie = selection[i]\n",
    "        if len(movie) > 3:\n",
    "            url = movie[3]\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                url = get_movie_url(movie)\n",
    "                movie.append(url)\n",
    "            except Exception as ex:\n",
    "                errored_movies.append([movie, ex])\n",
    "                continue\n",
    "        \n",
    "        try:\n",
    "            rs = get_reviews(url)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        all_movie_reviews[movie[0]] = rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kevin Carr': ['Kevin Carr',\n",
       "  '7M Pictures',\n",
       "  0.7,\n",
       "  'http://www.7mpictures.com/inside/reviews/stargatesg1childrenofthegodsdvd_review.htm'],\n",
       " 'New York Times': ['New York Times',\n",
       "  'New York Times',\n",
       "  None,\n",
       "  'http://movies.nytimes.com/2011/05/20/movies/children-of-god-review.html'],\n",
       " 'Peter Keough': ['Peter Keough',\n",
       "  'Boston Phoenix',\n",
       "  None,\n",
       "  'http://www.thephoenix.com/Boston/movies/101666-children-of-god/']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is funny. Rotten Tomatoes has reviews in the wrong places:\n",
    "# \n",
    "all_movie_reviews[\"Stargate SG-1 Children of the Gods - Final Cut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
